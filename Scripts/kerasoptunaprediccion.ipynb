{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Cargar dataset\n",
    "df = pd.read_csv(\"datasetwg_features.csv\")\n",
    "df['periodo'] = pd.to_datetime(df['periodo'])\n",
    "\n",
    "# 2. Codificar columnas categóricas\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# 3. Definir features y target\n",
    "features = [col for col in df.columns if col not in ['product_id', 'periodo', 'tn']]\n",
    "target = 'tn'\n",
    "\n",
    "# 4. Separar datos en train y validación\n",
    "df_train = df[df['periodo'] < '2019-12-01']\n",
    "df_val = df[df['periodo'] == '2019-12-01']\n",
    "\n",
    "X_train = df_train[features].astype(np.float32)\n",
    "y_train = df_train[target].astype(np.float32)\n",
    "X_val = df_val[features].astype(np.float32)\n",
    "y_val = df_val[target].astype(np.float32)\n",
    "\n",
    "# 5. Definir y entrenar modelo\n",
    "modelo = keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    layers.Dense(63, activation='relu'),\n",
    "    layers.Dense(28, activation='tanh'),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "modelo.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001552954889894353),\n",
    "               loss='mse')\n",
    "\n",
    "modelo.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1, validation_data=(X_val, y_val))\n",
    "\n",
    "# 6. Base para predicción enero (diciembre como input)\n",
    "df_pred_base = df[df['periodo'] == '2019-12-01'].copy()\n",
    "df_pred_base['periodo'] = pd.to_datetime('2020-01-01')\n",
    "\n",
    "X_enero = df_pred_base[features].astype(np.float32)\n",
    "df_pred_base['tn'] = modelo.predict(X_enero).flatten()\n",
    "\n",
    "# 7. Predicción febrero (enero como input)\n",
    "df_pred_feb = df_pred_base.copy()\n",
    "df_pred_feb['periodo'] = pd.to_datetime('2020-02-01')\n",
    "\n",
    "X_febrero = df_pred_feb[features].astype(np.float32)\n",
    "df_pred_feb['tn_predicho'] = modelo.predict(X_febrero).flatten()\n",
    "\n",
    "# 8. Exportar resultados\n",
    "resultado = df_pred_feb[['product_id', 'tn_predicho']]\n",
    "resultado.to_csv(\"prediccion_feb2020_keras.csv\", index=False)\n",
    "print(\"✅ Predicción guardada en prediccion_feb2020_keras.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a650a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "Index(['customer_id', 'product_id', 'periodo', 'plan_precios_cuidados',\n",
      "       'cust_request_qty', 'cust_request_tn', 'tn', 'stock_final', 'cat1',\n",
      "       'cat2', 'cat3', 'brand', 'sku_size', 'venta_id',\n",
      "       'DIFF(cust_request_qty)', 'DIFF(cust_request_tn)',\n",
      "       'DIFF(plan_precios_cuidados)', 'DIFF(sku_size)', 'DIFF(stock_final)',\n",
      "       'DIFF(tn)', 'LAG(brand, periodo)', 'LAG(cat1, periodo)',\n",
      "       'LAG(cat2, periodo)', 'LAG(cat3, periodo)',\n",
      "       'LAG(cust_request_qty, periodo)', 'LAG(cust_request_tn, periodo)',\n",
      "       'LAG(plan_precios_cuidados, periodo)', 'LAG(sku_size, periodo)',\n",
      "       'LAG(stock_final, periodo)', 'LAG(tn, periodo)', 'MONTH(periodo)',\n",
      "       'ROLLING_MEAN(periodo, cust_request_qty)',\n",
      "       'ROLLING_MEAN(periodo, cust_request_tn)',\n",
      "       'ROLLING_MEAN(periodo, plan_precios_cuidados)',\n",
      "       'ROLLING_MEAN(periodo, sku_size)', 'ROLLING_MEAN(periodo, stock_final)',\n",
      "       'ROLLING_MEAN(periodo, tn)', 'tn_lag_1', 'tn_lag_2', 'tn_lag_3',\n",
      "       'tn_lag_4', 'tn_lag_5', 'tn_delta', 'delta_tn_5', 'cat_delta_tn_lag_5',\n",
      "       'tn_lag_8', 'delta_tn_8', 'cat_delta_tn_lag_8', 'tn_lag_9',\n",
      "       'delta_tn_9', 'cat_delta_tn_lag_9', 'tn_lag_10', 'delta_tn_10',\n",
      "       'cat_delta_tn_lag_10', 'delta1_media_movil_3', 'tn_std_movil_1',\n",
      "       'tn_min_movil_3', 'delta1_media_movil_6', 'tn_std_movil_3',\n",
      "       'tn_min_movil_6', 'delta1_media_movil_12', 'tn_std_movil_6',\n",
      "       'tn_min_movil_12', 'avg_tn', 'total_total_tn_lag_9',\n",
      "       'total_total_tn_diff_4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columnas = pd.read_csv(\"datasetwg_features.csv\", nrows=0).columns\n",
    "print(len(columnas))\n",
    "print(columnas[:180])  # te muestra las primeras 20 columnas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "040b5ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9460980, 66)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99be6522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1863s\u001b[0m 3ms/step - loss: 2.7880 - val_loss: 2.4066\n",
      "Epoch 2/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1867s\u001b[0m 3ms/step - loss: 2.8486 - val_loss: 2.4055\n",
      "Epoch 3/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1888s\u001b[0m 3ms/step - loss: 2.8726 - val_loss: 2.4050\n",
      "Epoch 4/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1867s\u001b[0m 3ms/step - loss: 3.0098 - val_loss: 2.4061\n",
      "Epoch 5/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1060s\u001b[0m 2ms/step - loss: 2.9546 - val_loss: 2.4053\n",
      "Epoch 6/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 1ms/step - loss: 2.8664 - val_loss: 2.4052\n",
      "Epoch 7/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 1ms/step - loss: 2.7339 - val_loss: 2.4055\n",
      "Epoch 8/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m672s\u001b[0m 1ms/step - loss: 2.7774 - val_loss: 2.4062\n",
      "Epoch 9/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m672s\u001b[0m 1ms/step - loss: 2.8477 - val_loss: 2.4099\n",
      "Epoch 10/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 1ms/step - loss: 2.6374 - val_loss: 2.4061\n",
      "Epoch 11/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 1ms/step - loss: 2.8445 - val_loss: 2.4060\n",
      "Epoch 12/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m659s\u001b[0m 1ms/step - loss: 2.7362 - val_loss: 2.4045\n",
      "Epoch 13/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m676s\u001b[0m 1ms/step - loss: 2.8313 - val_loss: 2.4116\n",
      "Epoch 14/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 1ms/step - loss: 2.7205 - val_loss: 2.4068\n",
      "Epoch 15/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 1ms/step - loss: 3.0693 - val_loss: 2.4061\n",
      "Epoch 16/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m666s\u001b[0m 1ms/step - loss: 2.9442 - val_loss: 2.4084\n",
      "Epoch 17/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 1ms/step - loss: 2.6993 - val_loss: 2.4059\n",
      "Epoch 18/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m672s\u001b[0m 1ms/step - loss: 2.8290 - val_loss: 2.4064\n",
      "Epoch 19/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 1ms/step - loss: 2.7080 - val_loss: 2.4055\n",
      "Epoch 20/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 1ms/step - loss: 2.8440 - val_loss: 2.4046\n",
      "Epoch 21/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m677s\u001b[0m 1ms/step - loss: 2.9212 - val_loss: 2.4084\n",
      "Epoch 22/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 1ms/step - loss: 2.6632 - val_loss: 2.4056\n",
      "Epoch 23/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m736s\u001b[0m 1ms/step - loss: 2.8198 - val_loss: 2.4052\n",
      "Epoch 24/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m671s\u001b[0m 1ms/step - loss: 2.9764 - val_loss: 2.4061\n",
      "Epoch 25/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m675s\u001b[0m 1ms/step - loss: 2.6694 - val_loss: 2.4042\n",
      "Epoch 26/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12966s\u001b[0m 23ms/step - loss: 2.7491 - val_loss: 2.4071\n",
      "Epoch 27/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1841s\u001b[0m 3ms/step - loss: 2.6562 - val_loss: 2.4046\n",
      "Epoch 28/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m958s\u001b[0m 2ms/step - loss: 2.8471 - val_loss: 2.4044\n",
      "Epoch 29/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m859s\u001b[0m 1ms/step - loss: 2.7174 - val_loss: 2.4059\n",
      "Epoch 30/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 1ms/step - loss: 2.7869 - val_loss: 2.4058\n",
      "Epoch 31/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m674s\u001b[0m 1ms/step - loss: 2.8169 - val_loss: 2.4055\n",
      "Epoch 32/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 1ms/step - loss: 2.8237 - val_loss: 2.4062\n",
      "Epoch 33/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 1ms/step - loss: 2.8909 - val_loss: 2.4042\n",
      "Epoch 34/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1157s\u001b[0m 2ms/step - loss: 3.0599 - val_loss: 2.4053\n",
      "Epoch 35/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m843s\u001b[0m 1ms/step - loss: 2.8894 - val_loss: 2.4058\n",
      "Epoch 36/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1304s\u001b[0m 2ms/step - loss: 2.9176 - val_loss: 2.4052\n",
      "Epoch 37/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1162s\u001b[0m 2ms/step - loss: 2.7131 - val_loss: 2.4099\n",
      "Epoch 38/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1835s\u001b[0m 3ms/step - loss: 2.8809 - val_loss: 2.4052\n",
      "Epoch 39/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1336s\u001b[0m 2ms/step - loss: 2.9129 - val_loss: 2.4050\n",
      "Epoch 40/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m872s\u001b[0m 2ms/step - loss: 2.8732 - val_loss: 2.4061\n",
      "Epoch 41/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1615s\u001b[0m 3ms/step - loss: 2.7626 - val_loss: 2.4055\n",
      "Epoch 42/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2074s\u001b[0m 4ms/step - loss: 2.8741 - val_loss: 2.4100\n",
      "Epoch 43/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2019s\u001b[0m 4ms/step - loss: 2.8475 - val_loss: 2.4060\n",
      "Epoch 44/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1826s\u001b[0m 3ms/step - loss: 2.7863 - val_loss: 2.4051\n",
      "Epoch 45/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1465s\u001b[0m 3ms/step - loss: 2.6876 - val_loss: 2.4042\n",
      "Epoch 46/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1469s\u001b[0m 3ms/step - loss: 2.7260 - val_loss: 2.4196\n",
      "Epoch 47/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2324s\u001b[0m 4ms/step - loss: 2.9007 - val_loss: 2.4055\n",
      "Epoch 48/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1995s\u001b[0m 3ms/step - loss: 2.9066 - val_loss: 2.4063\n",
      "Epoch 49/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2101s\u001b[0m 4ms/step - loss: 2.9005 - val_loss: 2.4131\n",
      "Epoch 50/50\n",
      "\u001b[1m574886/574886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1781s\u001b[0m 3ms/step - loss: 2.6663 - val_loss: 2.4113\n",
      "\n",
      "✅ MSE validación dic-2019: 2.410806894302368\n",
      "📄 Archivo guardado: prediccion_feb2020_keras.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 1. CARGA EFICIENTE DEL CSV (float32 ↓ RAM)\n",
    "# ────────────────────────────────────────────────\n",
    "csv_path = \"datasetwg_features.csv\"\n",
    "\n",
    "# 1-A. Leer una muestra pequeña para detectar columnas numéricas\n",
    "sample = pd.read_csv(csv_path, nrows=5_000, low_memory=True)\n",
    "num_cols = sample.select_dtypes(include=[\"float64\", \"float32\", \"int64\", \"int32\"]).columns\n",
    "\n",
    "# 1-B. Armar diccionario dtype → float32 para esas columnas\n",
    "dtype_map = {c: \"float32\" for c in num_cols}\n",
    "\n",
    "# 1-C. Leer el CSV completo con esos dtypes (low_memory sigue en True)\n",
    "df = pd.read_csv(csv_path, dtype=dtype_map, low_memory=True,\n",
    "                 parse_dates=[\"periodo\"])        # “periodo” pasa directamente a datetime\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 2. CODIFICACIÓN DE CATEGÓRICAS (LabelEncoder)\n",
    "# ────────────────────────────────────────────────\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "for col in cat_cols:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 3. DEFINIR FEATURES & TARGET\n",
    "# ────────────────────────────────────────────────\n",
    "features = [c for c in df.columns if c not in [\"product_id\", \"periodo\", \"tn\"]]\n",
    "target   = \"tn\"\n",
    "\n",
    "# Split temporal: train hasta nov-2019, valid dic-2019\n",
    "df_train = df[df[\"periodo\"] <  \"2019-12-01\"]\n",
    "df_val   = df[df[\"periodo\"] == \"2019-12-01\"]\n",
    "\n",
    "X_train = df_train[features].astype(np.float32)\n",
    "y_train = df_train[target].astype(np.float32)\n",
    "X_val   = df_val[features].astype(np.float32)\n",
    "y_val   = df_val[target].astype(np.float32)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 4. MODELO KERAS CON HP ÓPTIMOS\n",
    "# ────────────────────────────────────────────────\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    layers.Dense(63, activation=\"relu\"),\n",
    "    layers.Dense(28, activation=\"tanh\"),\n",
    "    layers.Dense(1, activation=\"linear\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001552954889894353),\n",
    "    loss=\"mse\"\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50, batch_size=16, verbose=1,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "print(\"\\n✅ MSE validación dic-2019:\", model.evaluate(X_val, y_val, verbose=0))\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 5. PREDICCIÓN ENERO 2020 (diciembre como input)\n",
    "# ────────────────────────────────────────────────\n",
    "base_dic = df[df[\"periodo\"] == \"2019-12-01\"].copy()\n",
    "base_dic[\"periodo\"] = pd.to_datetime(\"2020-01-01\")\n",
    "\n",
    "X_enero = base_dic[features].astype(np.float32)\n",
    "base_dic[\"tn\"] = model.predict(X_enero, verbose=0).flatten()\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 6. PREDICCIÓN FEBRERO 2020 (enero como input)\n",
    "# ────────────────────────────────────────────────\n",
    "base_feb = base_dic.copy()\n",
    "base_feb[\"periodo\"] = pd.to_datetime(\"2020-02-01\")\n",
    "\n",
    "X_feb   = base_feb[features].astype(np.float32)\n",
    "base_feb[\"tn_predicho\"] = model.predict(X_feb, verbose=0).flatten()\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 7. EXPORTAR RESULTADOS\n",
    "# ────────────────────────────────────────────────\n",
    "out = base_feb[[\"product_id\", \"tn_predicho\"]]\n",
    "out.to_csv(\"prediccion_feb2020_keras.csv\", index=False)\n",
    "print(\"📄 Archivo guardado: prediccion_feb2020_keras.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d843648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados encontrados:\n",
      "        product_id  tn_predicho\n",
      "0          20001.0     0.173253\n",
      "1          20001.0     0.173253\n",
      "2          20001.0     0.173253\n",
      "3          20001.0     0.173253\n",
      "4          20001.0     0.173253\n",
      "...            ...          ...\n",
      "262800     21276.0     0.173253\n",
      "262801     21276.0     0.173253\n",
      "262802     21276.0     0.173253\n",
      "262803     21276.0     0.173253\n",
      "262804     21276.0     0.173253\n",
      "\n",
      "[262805 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar CSV\n",
    "df = pd.read_csv(\"prediccion_feb2020_keras.csv\")\n",
    "\n",
    "# Revisar duplicados\n",
    "duplicados = df[df.duplicated('product_id', keep=False)]\n",
    "print(\"Duplicados encontrados:\")\n",
    "print(duplicados)\n",
    "\n",
    "# Opción: quedarte con la predicción de mayor tn, menor, promedio, etc.\n",
    "# Acá usamos promedio por producto_id\n",
    "df_sin_duplicados = df.groupby('product_id', as_index=False).mean()\n",
    "\n",
    "# Guardar CSV corregido\n",
    "df_sin_duplicados.to_csv(\"prediccion_feb2020_keras_sin_duplicados.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optuna_keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
