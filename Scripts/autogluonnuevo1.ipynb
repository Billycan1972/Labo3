{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "883eb6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\waldo\\miniconda3\\envs\\autogluon-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü° Procesando chunks...\n",
      "‚úÖ Chunk 1: 500000 filas ‚Üí 500000 √∫tiles (acumuladas: 500000)\n",
      "‚úÖ Chunk 2: 405832 filas ‚Üí 405832 √∫tiles (acumuladas: 905832)\n",
      "‚úÖ Todos los chunks procesados. Total acumulado: 905832\n",
      "üì¶ Generando enero sint√©tico...\n",
      "üìù Archivo 'enero_fake_top30.csv' exportado para inspecci√≥n.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waldo\\AppData\\Local\\Temp\\ipykernel_15752\\410407547.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_train_con_enero = pd.concat([df_train, enero_fake], ignore_index=True)\n",
      "Beginning AutoGluon training... Time limit = 600s\n",
      "AutoGluon will save models to 'c:\\Users\\waldo\\Dropbox\\Maestr√≠a Ciencia de Datos\\Labo 3\\Proceso\\AutogluonModels\\ag-20250628_030622'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Entrenando modelo con AutoGluon...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.9.23\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       39.11 GB / 63.68 GB (61.4%)\n",
      "Disk Space Avail:   1350.52 GB / 1862.26 GB (72.5%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': RMSE,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 1,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'time_limit': 600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'IRREG' has been resampled to frequency 'MS'.\n",
      "Provided train_data has 2220 rows (NaN fraction=2.7%), 60 time series. Median time series length is 37 (min=37, max=37). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'RMSE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-06-28 00:06:35\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 45.0s of the 584.6s of remaining time.\n",
      "\tnan           = Validation score (-RMSE)\n",
      "\t0.16    s     = Training runtime\n",
      "\t7.33    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 48.1s of the 577.1s of remaining time.\n",
      "\tnan           = Validation score (-RMSE)\n",
      "\t7.84    s     = Training runtime\n",
      "\t0.13    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 51.7s of the 569.1s of remaining time.\n",
      "\tnan           = Validation score (-RMSE)\n",
      "\t6.89    s     = Training runtime\n",
      "\t0.20    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 56.2s of the 561.9s of remaining time.\n",
      "\tnan           = Validation score (-RMSE)\n",
      "\t0.10    s     = Training runtime\n",
      "\t0.22    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 62.4s of the 561.6s of remaining time.\n",
      "\tnan           = Validation score (-RMSE)\n",
      "\t0.11    s     = Training runtime\n",
      "\t5.39    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 69.5s of the 556.1s of remaining time.\n",
      "\tnan           = Validation score (-RMSE)\n",
      "\t0.10    s     = Training runtime\n",
      "\t0.92    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 79.3s of the 555.0s of remaining time.\n",
      "\tnan           = Validation score (-RMSE)\n",
      "\t13.58   s     = Training runtime\n",
      "\t11.18   s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 88.4s of the 530.2s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n",
      "\tSaving fine-tuned model to c:\\Users\\waldo\\Dropbox\\Maestr√≠a Ciencia de Datos\\Labo 3\\Proceso\\AutogluonModels\\ag-20250628_030622\\models\\ChronosFineTuned[bolt_small]\\W0\\fine-tuned-ckpt\n",
      "\tnan           = Validation score (-RMSE)\n",
      "\t73.73   s     = Training runtime\n",
      "\t0.31    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 91.2s of the 456.1s of remaining time.\n",
      "\tnan           = Validation score (-RMSE)\n",
      "\t88.41   s     = Training runtime\n",
      "\t0.17    s     = Validation (prediction) runtime\n",
      "Training timeseries model DeepAR. Training for up to 91.8s of the 367.2s of remaining time.\n",
      "\tWarning: Exception caused DeepAR to fail during training... Skipping this model.\n",
      "\t[WinError 32] El proceso no tiene acceso al archivo porque est√° siendo utilizado por otro proceso: 'c:\\\\Users\\\\waldo\\\\Dropbox\\\\Maestr√≠a Ciencia de Datos\\\\Labo 3\\\\Proceso\\\\AutogluonModels\\\\ag-20250628_030622\\\\models\\\\DeepAR\\\\W0\\\\lightning_logs\\\\version_0'\n",
      "Training timeseries model PatchTST. Training for up to 94.6s of the 283.9s of remaining time.\n",
      "\tnan           = Validation score (-RMSE)\n",
      "\t85.07   s     = Training runtime\n",
      "\t0.15    s     = Validation (prediction) runtime\n",
      "Training timeseries model TiDE. Training for up to 99.3s of the 198.7s of remaining time.\n",
      "\tnan           = Validation score (-RMSE)\n",
      "\t90.53   s     = Training runtime\n",
      "\t0.26    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tWarning: Exception caused ensemble to fail during training... Skipping this model.\n",
      "\t'a' cannot be empty unless no samples are taken\n",
      "Training complete. Models trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'PatchTST', 'TiDE']\n",
      "Total runtime: 479.62 s\n",
      "Best model: SeasonalNaive\n",
      "Best model score: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo entrenado.\n",
      "üîÆ Generando predicciones para febrero 2020...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data with frequency 'IRREG' has been resampled to frequency 'MS'.\n",
      "Model not specified in predict, will default to the model with the best validation score: SeasonalNaive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Columnas disponibles en predicciones: ['item_id', 'timestamp', 'mean', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9']\n",
      "‚úÖ Archivo exportado como 'prediccion_feb2020_autogluon_top30.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesPredictor\n",
    "\n",
    "# === 1. Cargar en chunks y filtrar hasta dic 2019 ===\n",
    "usecols = [\"product_id\", \"periodo\", \"tn\"]\n",
    "chunks = pd.read_csv(\"top_30_corr.csv\",\n",
    "                     usecols=usecols,\n",
    "                     parse_dates=[\"periodo\"],\n",
    "                     chunksize=500_000)\n",
    "\n",
    "filtrados = []\n",
    "total_rows = 0\n",
    "chunk_count = 0\n",
    "\n",
    "print(\"üü° Procesando chunks...\")\n",
    "for chunk in chunks:\n",
    "    chunk_count += 1\n",
    "    original_rows = len(chunk)\n",
    "    chunk = chunk[chunk[\"periodo\"] <= \"2019-12-01\"]\n",
    "    filtrados.append(chunk)\n",
    "    total_rows += len(chunk)\n",
    "    print(f\"‚úÖ Chunk {chunk_count}: {original_rows} filas ‚Üí {len(chunk)} √∫tiles (acumuladas: {total_rows})\")\n",
    "\n",
    "print(\"‚úÖ Todos los chunks procesados. Total acumulado:\", total_rows)\n",
    "\n",
    "# === 2. Renombrar y preparar ===\n",
    "df_train = pd.concat(filtrados, ignore_index=True)\n",
    "df_train = df_train.rename(columns={\"product_id\": \"item_id\", \"periodo\": \"timestamp\", \"tn\": \"target\"})\n",
    "df_train[\"item_id\"] = df_train[\"item_id\"].astype(str)\n",
    "\n",
    "# Forzar timestamps al inicio de mes (por si hay alg√∫n desv√≠o)\n",
    "df_train[\"timestamp\"] = df_train[\"timestamp\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "# === 3. Crear enero 2020 sint√©tico duplicando diciembre ===\n",
    "print(\"üì¶ Generando enero sint√©tico...\")\n",
    "enero_fake = df_train[df_train[\"timestamp\"] == \"2019-12-01\"].copy()\n",
    "enero_fake[\"timestamp\"] = pd.to_datetime(\"2020-01-01\")\n",
    "enero_fake[\"target\"] = pd.NA\n",
    "\n",
    "# üîÅ Guardar enero_fake para inspecci√≥n\n",
    "enero_fake.to_csv(\"enero_fake_top30.csv\", index=False)\n",
    "print(\"üìù Archivo 'enero_fake_top30.csv' exportado para inspecci√≥n.\")\n",
    "\n",
    "# === 4. Concatenar enero al dataset ===\n",
    "df_train_con_enero = pd.concat([df_train, enero_fake], ignore_index=True)\n",
    "df_train_con_enero = df_train_con_enero.sort_values([\"item_id\", \"timestamp\"])\n",
    "\n",
    "# === 5. Entrenar modelo ===\n",
    "print(\"‚öôÔ∏è Entrenando modelo con AutoGluon...\")\n",
    "predictor = TimeSeriesPredictor(\n",
    "    target=\"target\",\n",
    "    prediction_length=1,\n",
    "    eval_metric=\"RMSE\",\n",
    "    freq=\"MS\"  # ‚Üê CORRECCI√ìN CLAVE\n",
    ")\n",
    "predictor.fit(train_data=df_train_con_enero, time_limit=600)\n",
    "print(\"‚úÖ Modelo entrenado.\")\n",
    "\n",
    "# === 6. Predecir febrero 2020 ===\n",
    "print(\"üîÆ Generando predicciones para febrero 2020...\")\n",
    "predicciones = predictor.predict(df_train_con_enero)\n",
    "\n",
    "# === 7. Filtrar febrero 2020 ===\n",
    "resultado = predicciones.reset_index()\n",
    "print(\"üß™ Columnas disponibles en predicciones:\", resultado.columns.tolist())\n",
    "\n",
    "# Usamos la columna 'mean' como valor predicho\n",
    "resultado = resultado[resultado[\"timestamp\"] == pd.to_datetime(\"2020-02-01\")]\n",
    "resultado = resultado[[\"item_id\", \"mean\"]].rename(columns={\"item_id\": \"product_id\", \"mean\": \"tn_predicho\"})\n",
    "\n",
    "# === 8. Exportar resultado ===\n",
    "resultado.to_csv(\"prediccion_feb2020_autogluon_top30.csv\", index=False)\n",
    "print(\"‚úÖ Archivo exportado como 'prediccion_feb2020_autogluon_top30.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d808ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      periodo           tn\n",
      "31 2019-08-01  6763.956230\n",
      "32 2019-09-01  9211.424580\n",
      "33 2019-10-01  9392.195920\n",
      "34 2019-11-01  9015.628160\n",
      "35 2019-12-01  6586.565350\n",
      "36 2020-02-01    19.698087\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Cargar predicciones de Autogluon (febrero 2020)\n",
    "df_pred = pd.read_csv(\"prediccion_feb2020_autogluon_top30.csv\")  # asumimos que tiene 'product_id' y 'tn_predicha'\n",
    "total_predicho = df_pred[\"tn_predicho\"].sum()\n",
    "\n",
    "# 2. Cargar dataset base\n",
    "df_real = pd.read_csv(\"top_30_corr.csv\")\n",
    "df_real[\"periodo\"] = pd.to_datetime(df_real[\"periodo\"])\n",
    "\n",
    "# 3. Agrupar toneladas reales por per√≠odo\n",
    "tn_por_periodo = df_real.groupby(\"periodo\")[\"tn\"].sum().reset_index()\n",
    "\n",
    "# 4. Agregar predicci√≥n de febrero 2020 como nueva fila\n",
    "nueva_fila = pd.DataFrame({\"periodo\": [pd.Timestamp(\"2020-02-01\")], \"tn\": [total_predicho]})\n",
    "comparacion = pd.concat([tn_por_periodo, nueva_fila], ignore_index=True)\n",
    "\n",
    "# 5. Ordenar por per√≠odo\n",
    "comparacion = comparacion.sort_values(\"periodo\")\n",
    "\n",
    "# 6. Mostrar\n",
    "print(comparacion.tail(6))  # √∫ltimas filas para ver c√≥mo se compara febrero 2020\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
