{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84838ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'datasetwg.csv' cargado exitosamente.\n",
      "Columnas del dataset: ['customer_id', 'product_id', 'periodo', 'plan_precios_cuidados', 'cust_request_qty', 'cust_request_tn', 'tn', 'stock_final', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'venta_id', 'DIFF(cust_request_qty)', 'DIFF(cust_request_tn)', 'DIFF(plan_precios_cuidados)', 'DIFF(sku_size)', 'DIFF(stock_final)', 'DIFF(tn)', 'LAG(brand, periodo)', 'LAG(cat1, periodo)', 'LAG(cat2, periodo)', 'LAG(cat3, periodo)', 'LAG(cust_request_qty, periodo)', 'LAG(cust_request_tn, periodo)', 'LAG(plan_precios_cuidados, periodo)', 'LAG(sku_size, periodo)', 'LAG(stock_final, periodo)', 'LAG(tn, periodo)', 'MONTH(periodo)', 'ROLLING_MEAN(periodo, cust_request_qty)', 'ROLLING_MEAN(periodo, cust_request_tn)', 'ROLLING_MEAN(periodo, plan_precios_cuidados)', 'ROLLING_MEAN(periodo, sku_size)', 'ROLLING_MEAN(periodo, stock_final)', 'ROLLING_MEAN(periodo, tn)', 'tn_lag_1', 'tn_lag_2', 'tn_lag_3', 'tn_lag_4', 'tn_lag_5', 'tn_delta']\n",
      "Último periodo de datos disponible: 2019-12\n",
      "\n",
      "Calculando Predicción: Último mes (Dic 2019)...\n",
      "Predicción guardada en: predictions\\prediction_last_month_sales_feb_2020.csv\n",
      "\n",
      "Calculando Predicción: Promedio de los últimos 3 meses (Oct-Dic 2019)...\n",
      "Predicción guardada en: predictions\\prediction_avg_last_3m_sales_feb_2020.csv\n",
      "\n",
      "Calculando Predicción: Promedio de los últimos 6 meses (Jul-Dic 2019)...\n",
      "Predicción guardada en: predictions\\prediction_avg_last_6m_sales_feb_2020.csv\n",
      "\n",
      "Calculando Predicción: Promedio de los últimos 9 meses (Abr-Dic 2019)...\n",
      "Predicción guardada en: predictions\\prediction_avg_last_9m_sales_feb_2020.csv\n",
      "\n",
      "Calculando Predicción: Promedio de los últimos 12 meses (Ene-Dic 2019)...\n",
      "Predicción guardada en: predictions\\prediction_avg_last_12m_sales_feb_2020.csv\n",
      "\n",
      "Calculando Predicción: EMA de los últimos 3 meses (span=3)...\n",
      "Predicción guardada en: predictions\\prediction_ema_last_3m_sales_feb_2020_span3.csv\n",
      "\n",
      "Calculando Predicción: EMA de los últimos 6 meses (span=6)...\n",
      "Predicción guardada en: predictions\\prediction_ema_last_6m_sales_feb_2020_span6.csv\n",
      "\n",
      "Calculando Predicción: EMA de los últimos 9 meses (span=9)...\n",
      "Predicción guardada en: predictions\\prediction_ema_last_9m_sales_feb_2020_span9.csv\n",
      "\n",
      "Calculando Predicción: EMA de los últimos 12 meses (span=12)...\n",
      "Predicción guardada en: predictions\\prediction_ema_last_12m_sales_feb_2020_span12.csv\n",
      "\n",
      "Todas las predicciones triviales han sido generadas y guardadas en la carpeta 'predictions'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- 0. Configuración ---\n",
    "# Crea la carpeta 'predictions' si no existe\n",
    "output_folder = \"predictions\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# --- 1. Cargar el Dataset ---\n",
    "# ¡IMPORTANTE!: Asegúrate de que 'datasetwg.csv' esté en la misma carpeta que este script,\n",
    "# o proporciona la ruta completa al archivo (ej. \"C:/Users/TuUsuario/Documentos/datasetwg.csv\").\n",
    "try:\n",
    "    df_raw = pd.read_csv(\"datasetwg.csv\")\n",
    "    print(\"Dataset 'datasetwg.csv' cargado exitosamente.\")\n",
    "    print(f\"Columnas del dataset: {df_raw.columns.tolist()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"¡ERROR!: No se encontró el archivo 'datasetwg.csv'. Por favor, asegúrate de que la ruta sea correcta.\")\n",
    "    print(\"El script continuará con un DataFrame de ejemplo, pero los resultados no serán sobre tus datos reales.\")\n",
    "    # Creando un DataFrame de ejemplo para que el script no falle inmediatamente\n",
    "    data = {\n",
    "        'periodo': pd.to_datetime(['2017-01-01', '2017-02-01', '2019-10-01', '2019-11-01', '2019-12-01'] * 5),\n",
    "        'customer_id': ['C101', 'C102', 'C103', 'C101', 'C102'] * 5,\n",
    "        'product_id': ['P001', 'P002', 'P001', 'P003', 'P002'] * 5,\n",
    "        'tn': np.random.randint(10, 1000, 25)\n",
    "    }\n",
    "    df_raw = pd.DataFrame(data)\n",
    "    # Ajustar periodos para el ejemplo\n",
    "    df_raw['periodo'] = df_raw['periodo'].dt.to_period('M') # Convertir a PeriodDtype para facilitar comparaciones de meses\n",
    "\n",
    "\n",
    "# --- 2. Preprocesamiento de Datos ---\n",
    "# Convertir la columna 'periodo' a formato de fecha si no lo está\n",
    "# Asumimos que 'periodo' está en un formato que pandas puede interpretar (YYYY-MM-DD o YYYY-MM)\n",
    "df_raw['periodo'] = pd.to_datetime(df_raw['periodo'])\n",
    "df_raw['periodo'] = df_raw['periodo'].dt.to_period('M') # Convertir a PeriodDtype para facilitar comparaciones de meses\n",
    "\n",
    "# Agrupar las ventas (tn) por periodo y product_id, sumando todos los customer_id\n",
    "df_agg = df_raw.groupby(['periodo', 'product_id'])['tn'].sum().reset_index()\n",
    "\n",
    "# Ordenar por periodo para asegurar cálculos de series temporales correctos\n",
    "df_agg = df_agg.sort_values(by=['periodo', 'product_id']).reset_index(drop=True)\n",
    "\n",
    "# Obtener el último periodo disponible (Diciembre 2019)\n",
    "last_period_data = df_agg['periodo'].max()\n",
    "print(f\"Último periodo de datos disponible: {last_period_data}\")\n",
    "\n",
    "# Definir el periodo de predicción (Febrero 2020)\n",
    "prediction_period = pd.Period('2020-02', freq='M')\n",
    "\n",
    "# --- 3. Implementación de Predicciones Triviales ---\n",
    "\n",
    "# Función para guardar los resultados\n",
    "def save_prediction(df_prediction, filename):\n",
    "    filepath = os.path.join(output_folder, filename)\n",
    "    df_prediction.to_csv(filepath, index=False)\n",
    "    print(f\"Predicción guardada en: {filepath}\")\n",
    "\n",
    "# 3.1. Predicción: Último mes (Diciembre 2019)\n",
    "print(\"\\nCalculando Predicción: Último mes (Dic 2019)...\")\n",
    "df_last_month = df_agg[df_agg['periodo'] == last_period_data].copy()\n",
    "df_last_month = df_last_month[['product_id', 'tn']].rename(columns={'tn': 'predicted_tn_feb_2020'})\n",
    "save_prediction(df_last_month, \"prediction_last_month_sales_feb_2020.csv\")\n",
    "\n",
    "# 3.2. Predicción: Promedio de los últimos 3 meses (Oct-Dic 2019)\n",
    "print(\"\\nCalculando Predicción: Promedio de los últimos 3 meses (Oct-Dic 2019)...\")\n",
    "# Calcular la fecha límite inferior para los 3 meses\n",
    "end_date_3m = pd.Period('2019-12', freq='M')\n",
    "start_date_3m = pd.Period('2019-10', freq='M')\n",
    "\n",
    "df_3m_avg = df_agg[(df_agg['periodo'] >= start_date_3m) & (df_agg['periodo'] <= end_date_3m)]\n",
    "# Agrupar por product_id y calcular el promedio de 'tn'\n",
    "prediction_3m_avg = df_3m_avg.groupby('product_id')['tn'].mean().reset_index()\n",
    "prediction_3m_avg.rename(columns={'tn': 'predicted_tn_feb_2020'}, inplace=True)\n",
    "save_prediction(prediction_3m_avg, \"prediction_avg_last_3m_sales_feb_2020.csv\")\n",
    "\n",
    "# 3.3. Predicción: Promedio de los últimos 6 meses (Jul-Dic 2019)\n",
    "print(\"\\nCalculando Predicción: Promedio de los últimos 6 meses (Jul-Dic 2019)...\")\n",
    "end_date_6m = pd.Period('2019-12', freq='M')\n",
    "start_date_6m = pd.Period('2019-07', freq='M')\n",
    "\n",
    "df_6m_avg = df_agg[(df_agg['periodo'] >= start_date_6m) & (df_agg['periodo'] <= end_date_6m)]\n",
    "prediction_6m_avg = df_6m_avg.groupby('product_id')['tn'].mean().reset_index()\n",
    "prediction_6m_avg.rename(columns={'tn': 'predicted_tn_feb_2020'}, inplace=True)\n",
    "save_prediction(prediction_6m_avg, \"prediction_avg_last_6m_sales_feb_2020.csv\")\n",
    "\n",
    "# 3.4. Predicción: Promedio de los últimos 9 meses (Abr-Dic 2019)\n",
    "print(\"\\nCalculando Predicción: Promedio de los últimos 9 meses (Abr-Dic 2019)...\")\n",
    "end_date_9m = pd.Period('2019-12', freq='M')\n",
    "start_date_9m = pd.Period('2019-04', freq='M')\n",
    "\n",
    "df_9m_avg = df_agg[(df_agg['periodo'] >= start_date_9m) & (df_agg['periodo'] <= end_date_9m)]\n",
    "prediction_9m_avg = df_9m_avg.groupby('product_id')['tn'].mean().reset_index()\n",
    "prediction_9m_avg.rename(columns={'tn': 'predicted_tn_feb_2020'}, inplace=True)\n",
    "save_prediction(prediction_9m_avg, \"prediction_avg_last_9m_sales_feb_2020.csv\")\n",
    "\n",
    "# 3.5. Predicción: Promedio de los últimos 12 meses (Ene-Dic 2019)\n",
    "print(\"\\nCalculando Predicción: Promedio de los últimos 12 meses (Ene-Dic 2019)...\")\n",
    "end_date_12m = pd.Period('2019-12', freq='M')\n",
    "start_date_12m = pd.Period('2019-01', freq='M')\n",
    "\n",
    "df_12m_avg = df_agg[(df_agg['periodo'] >= start_date_12m) & (df_agg['periodo'] <= end_date_12m)]\n",
    "prediction_12m_avg = df_12m_avg.groupby('product_id')['tn'].mean().reset_index()\n",
    "prediction_12m_avg.rename(columns={'tn': 'predicted_tn_feb_2020'}, inplace=True)\n",
    "save_prediction(prediction_12m_avg, \"prediction_avg_last_12m_sales_feb_2020.csv\")\n",
    "\n",
    "# --- Funciones para Media Móvil Exponencial (EMA) ---\n",
    "# La EMA se calcula generalmente sobre una serie temporal. Para cada product_id,\n",
    "# necesitamos calcular la EMA de su historial de ventas 'tn'.\n",
    "\n",
    "def calculate_ema_prediction(df_data, periods, span_value, name_suffix):\n",
    "    print(f\"\\nCalculando Predicción: EMA de los últimos {periods} meses (span={span_value})...\")\n",
    "    # Para cada product_id, aplicar la EMA\n",
    "    # Primero, necesitamos asegurarnos de que tenemos todos los meses para cada product_id si es necesario,\n",
    "    # o que la ventana de EMA solo considere los meses existentes.\n",
    "    # Aquí, calculamos la EMA por product_id y luego tomamos el último valor disponible de la EMA.\n",
    "\n",
    "    # Obtener el historial para el cálculo de la EMA\n",
    "    if periods == 3:\n",
    "        ema_df = df_data[(df_data['periodo'] >= pd.Period('2019-10', freq='M')) & (df_data['periodo'] <= pd.Period('2019-12', freq='M'))]\n",
    "    elif periods == 6:\n",
    "        ema_df = df_data[(df_data['periodo'] >= pd.Period('2019-07', freq='M')) & (df_data['periodo'] <= pd.Period('2019-12', freq='M'))]\n",
    "    elif periods == 9:\n",
    "        ema_df = df_data[(df_data['periodo'] >= pd.Period('2019-04', freq='M')) & (df_data['periodo'] <= pd.Period('2019-12', freq='M'))]\n",
    "    elif periods == 12:\n",
    "        ema_df = df_data[(df_data['periodo'] >= pd.Period('2019-01', freq='M')) & (df_data['periodo'] <= pd.Period('2019-12', freq='M'))]\n",
    "    else:\n",
    "        print(f\"Error: Número de periodos ({periods}) no soportado para EMA. Debe ser 3, 6, 9 o 12.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Si hay product_id sin datos en el rango, no se calculará EMA para ellos.\n",
    "    # Para EMA, necesitamos el último valor calculado.\n",
    "    # Agrupamos por product_id, ordenamos por periodo y aplicamos ewm.\n",
    "    prediction_ema = ema_df.groupby('product_id')['tn'].apply(lambda x: x.ewm(span=span_value, adjust=False).mean().iloc[-1] if not x.empty else np.nan).reset_index()\n",
    "    prediction_ema.rename(columns={'tn': 'predicted_tn_feb_2020'}, inplace=True)\n",
    "    # Eliminar NaN si algún product_id no tiene suficientes datos para el cálculo\n",
    "    prediction_ema.dropna(subset=['predicted_tn_feb_2020'], inplace=True)\n",
    "    save_prediction(prediction_ema, f\"prediction_ema_last_{periods}m_sales_feb_2020{name_suffix}.csv\")\n",
    "\n",
    "# 3.6. Predicción: Media Móvil Exponencial (EMA) de los últimos 3 meses\n",
    "# 'span' se refiere al número de períodos de la ventana de la EMA.\n",
    "calculate_ema_prediction(df_agg, 3, 3, \"_span3\")\n",
    "\n",
    "# 3.7. Predicción: Media Móvil Exponencial (EMA) de los últimos 6 meses\n",
    "calculate_ema_prediction(df_agg, 6, 6, \"_span6\")\n",
    "\n",
    "# 3.8. Predicción: Media Móvil Exponencial (EMA) de los últimos 9 meses\n",
    "calculate_ema_prediction(df_agg, 9, 9, \"_span9\")\n",
    "\n",
    "# 3.9. Predicción: Media Móvil Exponencial (EMA) de los últimos 12 meses\n",
    "calculate_ema_prediction(df_agg, 12, 12, \"_span12\")\n",
    "\n",
    "print(\"\\nTodas las predicciones triviales han sido generadas y guardadas en la carpeta 'predictions'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b59f8da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando ensemble entre los promedios...\n",
      "Ensemble de promedios guardado en: predictions\\ensemble_average_predictions_feb_2020.csv\n",
      "\n",
      "Realizando ensemble entre las EMAs...\n",
      "Ensemble de EMAs guardado en: predictions\\ensemble_ema_predictions_feb_2020.csv\n",
      "\n",
      "Proceso de ensemble finalizado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 0. Configuración ---\n",
    "# La carpeta donde se guardaron las predicciones individuales del script anterior.\n",
    "# Asegúrate de que esta carpeta exista y contenga los CSVs de las predicciones.\n",
    "output_folder = \"predictions\" \n",
    "\n",
    "# --- 1. Ensemble entre los Promedios ---\n",
    "print(\"Realizando ensemble entre los promedios...\")\n",
    "\n",
    "# Lista de archivos de predicción basados en promedios\n",
    "avg_files = [\n",
    "    \"prediction_avg_last_3m_sales_feb_2020.csv\",\n",
    "    \"prediction_avg_last_6m_sales_feb_2020.csv\",\n",
    "    \"prediction_avg_last_9m_sales_feb_2020.csv\",\n",
    "    \"prediction_avg_last_12m_sales_feb_2020.csv\"\n",
    "]\n",
    "\n",
    "# DataFrame para almacenar todas las predicciones de promedio\n",
    "all_avg_predictions = pd.DataFrame()\n",
    "\n",
    "for file_name in avg_files:\n",
    "    file_path = os.path.join(output_folder, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        df_temp = pd.read_csv(file_path)\n",
    "        # Renombrar la columna de predicción para evitar conflictos al hacer merge\n",
    "        # Usamos un nombre único basado en el nombre del archivo original\n",
    "        df_temp.rename(columns={'predicted_tn_feb_2020': f'pred_{file_name.replace(\".csv\", \"\")}'}, inplace=True)\n",
    "        \n",
    "        if all_avg_predictions.empty:\n",
    "            # Si es el primer archivo, inicializar el DataFrame\n",
    "            all_avg_predictions = df_temp[['product_id', f'pred_{file_name.replace(\".csv\", \"\")}']]\n",
    "        else:\n",
    "            # Para los archivos subsiguientes, hacer un merge por 'product_id'\n",
    "            all_avg_predictions = pd.merge(all_avg_predictions, df_temp[['product_id', f'pred_{file_name.replace(\".csv\", \"\")}']], on='product_id', how='outer')\n",
    "    else:\n",
    "        print(f\"Advertencia: No se encontró el archivo {file_name} en '{output_folder}'. Se omitirá en el ensemble de promedios.\")\n",
    "\n",
    "if not all_avg_predictions.empty:\n",
    "    # Obtener solo las columnas que contienen las predicciones (las que empiezan con 'pred_')\n",
    "    prediction_columns = [col for col in all_avg_predictions.columns if col.startswith('pred_')]\n",
    "    # Calcular el promedio de esas columnas para cada product_id\n",
    "    all_avg_predictions['ensemble_avg_tn_feb_2020'] = all_avg_predictions[prediction_columns].mean(axis=1)\n",
    "\n",
    "    # Seleccionar solo 'product_id' y la nueva columna de ensemble final\n",
    "    ensemble_avg_result = all_avg_predictions[['product_id', 'ensemble_avg_tn_feb_2020']]\n",
    "\n",
    "    # Guardar el resultado del ensemble de promedios\n",
    "    ensemble_avg_file_path = os.path.join(output_folder, \"ensemble_average_predictions_feb_2020.csv\")\n",
    "    ensemble_avg_result.to_csv(ensemble_avg_file_path, index=False)\n",
    "    print(f\"Ensemble de promedios guardado en: {ensemble_avg_file_path}\")\n",
    "else:\n",
    "    print(\"No se pudieron cargar suficientes archivos de promedio para realizar el ensemble. Verifique la existencia de los archivos.\")\n",
    "\n",
    "# --- 2. Ensemble entre las EMAs ---\n",
    "print(\"\\nRealizando ensemble entre las EMAs...\")\n",
    "\n",
    "# Lista de archivos de predicción basados en EMAs\n",
    "ema_files = [\n",
    "    \"prediction_ema_last_3m_sales_feb_2020_span3.csv\",\n",
    "    \"prediction_ema_last_6m_sales_feb_2020_span6.csv\",\n",
    "    \"prediction_ema_last_9m_sales_feb_2020_span9.csv\",\n",
    "    \"prediction_ema_last_12m_sales_feb_2020_span12.csv\"\n",
    "]\n",
    "\n",
    "# DataFrame para almacenar todas las predicciones de EMA\n",
    "all_ema_predictions = pd.DataFrame()\n",
    "\n",
    "for file_name in ema_files:\n",
    "    file_path = os.path.join(output_folder, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        df_temp = pd.read_csv(file_path)\n",
    "        # Renombrar la columna de predicción para evitar conflictos al hacer merge\n",
    "        df_temp.rename(columns={'predicted_tn_feb_2020': f'pred_{file_name.replace(\".csv\", \"\")}'}, inplace=True)\n",
    "        \n",
    "        if all_ema_predictions.empty:\n",
    "            all_ema_predictions = df_temp[['product_id', f'pred_{file_name.replace(\".csv\", \"\")}']]\n",
    "        else:\n",
    "            all_ema_predictions = pd.merge(all_ema_predictions, df_temp[['product_id', f'pred_{file_name.replace(\".csv\", \"\")}']], on='product_id', how='outer')\n",
    "    else:\n",
    "        print(f\"Advertencia: No se encontró el archivo {file_name} en '{output_folder}'. Se omitirá en el ensemble de EMAs.\")\n",
    "\n",
    "if not all_ema_predictions.empty:\n",
    "    # Obtener solo las columnas que contienen las predicciones\n",
    "    prediction_columns = [col for col in all_ema_predictions.columns if col.startswith('pred_')]\n",
    "    # Calcular el promedio de esas columnas para cada product_id\n",
    "    all_ema_predictions['ensemble_ema_tn_feb_2020'] = all_ema_predictions[prediction_columns].mean(axis=1)\n",
    "\n",
    "    # Seleccionar solo 'product_id' y la nueva columna de ensemble final\n",
    "    ensemble_ema_result = all_ema_predictions[['product_id', 'ensemble_ema_tn_feb_2020']]\n",
    "\n",
    "    # Guardar el resultado del ensemble de EMAs\n",
    "    ensemble_ema_file_path = os.path.join(output_folder, \"ensemble_ema_predictions_feb_2020.csv\")\n",
    "    ensemble_ema_result.to_csv(ensemble_ema_file_path, index=False)\n",
    "    print(f\"Ensemble de EMAs guardado en: {ensemble_ema_file_path}\")\n",
    "else:\n",
    "    print(\"No se pudieron cargar suficientes archivos de EMA para realizar el ensemble. Verifique la existencia de los archivos.\")\n",
    "\n",
    "print(\"\\nProceso de ensemble finalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f69cd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'datasetwg.csv' cargado exitosamente.\n",
      "\n",
      "Calculando Predicción: Promedio de los últimos 18 meses (Jul 2018 - Dic 2019)...\n",
      "Predicción de promedio de los últimos 18 meses guardada en: predictions\\prediction_avg_last_18m_sales_feb_2020.csv\n",
      "\n",
      "Proceso de predicción finalizado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- 0. Configuración ---\n",
    "# Crea la carpeta 'predictions' si no existe\n",
    "output_folder = \"predictions\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# --- 1. Cargar el Dataset ---\n",
    "# Asegúrate de que 'datasetwg.csv' esté en la misma carpeta que este script,\n",
    "# o proporciona la ruta completa al archivo (ej. \"C:/Users/TuUsuario/Documentos/datasetwg.csv\").\n",
    "try:\n",
    "    df_raw = pd.read_csv(\"datasetwg.csv\")\n",
    "    print(\"Dataset 'datasetwg.csv' cargado exitosamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"¡ERROR!: No se encontró el archivo 'datasetwg.csv'. Por favor, asegúrate de que la ruta sea correcta.\")\n",
    "    print(\"El script continuará con un DataFrame de ejemplo para fines demostrativos.\")\n",
    "    # Creando un DataFrame de ejemplo si el archivo no se encuentra\n",
    "    data = {\n",
    "        'periodo': pd.to_datetime([f'2018-{m:02d}-01' for m in range(7, 13)] + [f'2019-{m:02d}-01' for m in range(1, 13)] * 2), # 18 meses\n",
    "        'customer_id': ['C101', 'C102', 'C103'] * 12,\n",
    "        'product_id': ['P001', 'P002', 'P003', 'P001', 'P002', 'P003'] * 6,\n",
    "        'tn': np.random.randint(50, 1500, 36)\n",
    "    }\n",
    "    df_raw = pd.DataFrame(data)\n",
    "    df_raw['periodo'] = df_raw['periodo'].dt.to_period('M')\n",
    "\n",
    "\n",
    "# --- 2. Preprocesamiento de Datos ---\n",
    "# Convertir la columna 'periodo' a formato de fecha si no lo está\n",
    "df_raw['periodo'] = pd.to_datetime(df_raw['periodo'])\n",
    "df_raw['periodo'] = df_raw['periodo'].dt.to_period('M') # Convertir a PeriodDtype para facilitar comparaciones\n",
    "\n",
    "# Agrupar las ventas (tn) por periodo y product_id, sumando todos los customer_id\n",
    "df_agg = df_raw.groupby(['periodo', 'product_id'])['tn'].sum().reset_index()\n",
    "\n",
    "# Ordenar por periodo para asegurar cálculos de series temporales correctos\n",
    "df_agg = df_agg.sort_values(by=['periodo', 'product_id']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- 3. Predicción: Promedio de los últimos 18 meses (Jul 2018 - Dic 2019) ---\n",
    "print(\"\\nCalculando Predicción: Promedio de los últimos 18 meses (Jul 2018 - Dic 2019)...\")\n",
    "\n",
    "# Definir el rango de fechas para los últimos 18 meses\n",
    "end_date_18m = pd.Period('2019-12', freq='M')\n",
    "start_date_18m = pd.Period('2018-07', freq='M') # 18 meses antes de 2019-12\n",
    "\n",
    "df_18m_avg = df_agg[(df_agg['periodo'] >= start_date_18m) & (df_agg['periodo'] <= end_date_18m)]\n",
    "\n",
    "if not df_18m_avg.empty:\n",
    "    # Agrupar por product_id y calcular el promedio de 'tn'\n",
    "    prediction_18m_avg = df_18m_avg.groupby('product_id')['tn'].mean().reset_index()\n",
    "    prediction_18m_avg.rename(columns={'tn': 'predicted_tn_feb_2020'}, inplace=True)\n",
    "\n",
    "    # Guardar el resultado\n",
    "    filepath_18m_avg = os.path.join(output_folder, \"prediction_avg_last_18m_sales_feb_2020.csv\")\n",
    "    prediction_18m_avg.to_csv(filepath_18m_avg, index=False)\n",
    "    print(f\"Predicción de promedio de los últimos 18 meses guardada en: {filepath_18m_avg}\")\n",
    "else:\n",
    "    print(f\"No se encontraron datos para el rango de {start_date_18m} a {end_date_18m}. No se pudo calcular la predicción.\")\n",
    "\n",
    "print(\"\\nProceso de predicción finalizado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuevito",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
